{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86662550",
   "metadata": {},
   "source": [
    "# Task 4 Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fcd416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 17:55:03.039137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks, metrics, regularizers\n",
    "from tensorflow.keras.layers import Concatenate, Input\n",
    "\n",
    "def load_and_combine_data(filenames):\n",
    "    data_frames = []\n",
    "    for file in filenames:\n",
    "        df = pd.read_csv(file, sep='\\t')\n",
    "        data_frames.append(df)\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def train_val_split(df, type_col='Type', target_col='GenreID'):\n",
    "    train_data = df[df[type_col] == 'Train']\n",
    "    test_data = df[df[type_col] == 'Test']\n",
    "    X_train = train_data.drop([type_col, target_col], axis=1)\n",
    "    y_train = train_data[target_col]\n",
    "    X_test = test_data.drop([type_col, target_col], axis=1)\n",
    "    y_test = test_data[target_col]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6042a09",
   "metadata": {},
   "source": [
    "Step 1: choose which dataset to include (include path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cca6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = ['data/GenreClassData_10s.txt','data/GenreClassData_30s.txt','data/GenreClassData_5s.txt'] #  ,, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b7f03",
   "metadata": {},
   "source": [
    "Step 2: load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63dea406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataframe shape: (9900, 65)\n"
     ]
    }
   ],
   "source": [
    "df = load_and_combine_data(data_paths)\n",
    "feature_columns = [col for col in df.columns if col not in ['Type', 'GenreID', 'Genre', 'Track ID', 'File']]\n",
    "\n",
    "df = df[['Type', 'GenreID'] + feature_columns] # keeping only relevent columns\n",
    "\n",
    "print(\"Combined Dataframe shape:\", df.shape) \n",
    "\n",
    "X_train_scaled, y_train, X_test_scaled, y_test = train_val_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff74e49",
   "metadata": {},
   "source": [
    "# 1. Fully Connected Neural Network (FCNN) Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ecb83f",
   "metadata": {},
   "source": [
    "### 1.1 Create FCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d595e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "fcnn = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e4009",
   "metadata": {},
   "source": [
    "### 1.1.1 Alternative FCNN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ef3f5",
   "metadata": {},
   "source": [
    "### Deep and Wide FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fb85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_wide_fcnn = models.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "deep_wide_fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5feb3",
   "metadata": {},
   "source": [
    "### Shallow Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31454dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_fcnn = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "shallow_fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89604bb6",
   "metadata": {},
   "source": [
    "### FCNN with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e4f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_fcnn = models.Sequential([\n",
    "    layers.Dense(128, input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "bn_fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b471e6",
   "metadata": {},
   "source": [
    "### FCNN with Alternative Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46224ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_act_fcnn = models.Sequential([\n",
    "    layers.Dense(128, activation='elu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='elu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='elu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "alt_act_fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8cfd13",
   "metadata": {},
   "source": [
    "### FCNN with L1/L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddc4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fcnn = models.Sequential([\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "reg_fcnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be5a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd44378",
   "metadata": {},
   "source": [
    "### 1.2 Train FCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f9985",
   "metadata": {},
   "source": [
    "simply change the \"model\" parameter to change the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f5096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deep_wide_fcnn # name of the model to be trained here\n",
    "\n",
    "history_fcnn = model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled, y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"FCNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc228f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e708ea0",
   "metadata": {},
   "source": [
    "# 2. Convolutional Neural Network (CNN) Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0ab62",
   "metadata": {},
   "source": [
    "### 2.1 Reshape data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b391564",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n",
    "X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054d96d",
   "metadata": {},
   "source": [
    "### 2.2 Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c696950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv1D(32, 3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd65662",
   "metadata": {},
   "source": [
    "### 2.2.1 Alternative CNN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e02990",
   "metadata": {},
   "source": [
    "### Increased Depth and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_cnn = models.Sequential([\n",
    "    layers.Conv1D(64, 3, activation='relu', padding='same', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "deep_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11db8a",
   "metadata": {},
   "source": [
    "### CNN with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36d84346",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_cnn = models.Sequential([\n",
    "    layers.Conv1D(32, 3, padding='same', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 3, padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "bn_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce51fa",
   "metadata": {},
   "source": [
    "### CNN with Dilated Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eade1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_cnn = models.Sequential([\n",
    "    layers.Conv1D(32, 3, dilation_rate=1, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.Conv1D(32, 3, dilation_rate=2, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 3, dilation_rate=2, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "dilated_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0326f35",
   "metadata": {},
   "source": [
    "### CNN with Inception Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ee4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(input_tensor, filter_operation):\n",
    "    t1 = layers.Conv1D(filter_operation, 1, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    t2 = layers.Conv1D(filter_operation, 1, padding='same', activation='relu')(input_tensor)\n",
    "    t2 = layers.Conv1D(filter_operation, 3, padding='same', activation='relu')(t2)\n",
    "\n",
    "    t3 = layers.Conv1D(filter_operation, 1, padding='same', activation='relu')(input_tensor)\n",
    "    t3 = layers.Conv1D(filter_operation, 5, padding='same', activation='relu')(t3)\n",
    "\n",
    "    t4 = layers.MaxPooling1D(3, strides=1, padding='same')(input_tensor)\n",
    "    t4 = layers.Conv1D(filter_operation, 1, padding='same', activation='relu')(t4)\n",
    "\n",
    "    output = layers.Concatenate()([t1, t2, t3, t4])\n",
    "    return output\n",
    "\n",
    "input_layer = Input(shape=(X_train_scaled.shape[1], 1))\n",
    "x = inception_module(input_layer, 32)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = inception_module(x, 64)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "inception_cnn = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "inception_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c49e0",
   "metadata": {},
   "source": [
    "### Lightweight CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1441810",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightweight_cnn = models.Sequential([\n",
    "    layers.Conv1D(16, 3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(16, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "lightweight_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56466f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5797341f",
   "metadata": {},
   "source": [
    "### 2.3 Train CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377833e",
   "metadata": {},
   "source": [
    "simply change the \"model\" parameter to change the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bn_cnn # name of the model to be trained here\n",
    "\n",
    "history_cnn = model.fit(X_train_cnn, y_train, epochs=10, validation_data=(X_test_cnn, y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test_cnn, y_test, verbose=2)\n",
    "print(f\"CNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f4379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33185140",
   "metadata": {},
   "source": [
    "# 3. Recurrent Neural Network (RNN) Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a4177",
   "metadata": {},
   "source": [
    "### 3.1 Reshape data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccece180",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rnn = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_rnn = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07bac6",
   "metadata": {},
   "source": [
    "### 3.2 Create RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2283e533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "rnn = models.Sequential([\n",
    "    layers.LSTM(64, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b765fa4",
   "metadata": {},
   "source": [
    "### 3.2.1 Alternative RNN architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621203f9",
   "metadata": {},
   "source": [
    "### Simple RNN with Increased Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57388270",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = models.Sequential([\n",
    "    layers.SimpleRNN(64, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(64),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "simple_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fee102",
   "metadata": {},
   "source": [
    "### LSTM with Bidirectional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98d6f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "bidirectional_lstm = models.Sequential([\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(1, X_train_scaled.shape[1])),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "bidirectional_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c460c",
   "metadata": {},
   "source": [
    "### GRU with Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a20305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = models.Sequential([\n",
    "    layers.GRU(64, return_sequences=True, input_shape=(1, X_train_scaled.shape[1]), recurrent_initializer='glorot_uniform'),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.GRU(64),\n",
    "    layers.LayerNormalization(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "gru.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a5aa1",
   "metadata": {},
   "source": [
    "### Stacked LSTM with Different Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83356964",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_lstm = models.Sequential([\n",
    "    layers.LSTM(128, return_sequences=True, input_shape=(1, X_train_scaled.shape[1])),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.LSTM(32),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "stacked_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28784e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ab2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd18ddf5",
   "metadata": {},
   "source": [
    "### 3.3 Train RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7643a9",
   "metadata": {},
   "source": [
    "simply change the \"model\" parameter to change the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885c475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = bidirectional_lstm # name of the model to be trained here\n",
    "\n",
    "history_rnn = model.fit(X_train_rnn, y_train, epochs=20, validation_data=(X_test_rnn, y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test_rnn, y_test, verbose=2)\n",
    "print(f\"RNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2908628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47aad2d0",
   "metadata": {},
   "source": [
    "# 4. Hybrid models Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f0689c",
   "metadata": {},
   "source": [
    "### CNN + LSTM Model (it's bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57894434",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_cnn_lstm_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "hybrid_cnn_lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a70a05",
   "metadata": {},
   "source": [
    "### LSTM + Conv1D Model (slow to train and overfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f53dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_lstm_cnn_model = models.Sequential([\n",
    "    layers.LSTM(64, return_sequences=True, input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.LSTM(64),\n",
    "    layers.Reshape((64, 1)),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "hybrid_lstm_cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4354e",
   "metadata": {},
   "source": [
    "### CNN + GRU Model (overfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46aa9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_cnn_gru_model = models.Sequential([\n",
    "    layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.GRU(64, return_sequences=True),\n",
    "    layers.GRU(64),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "hybrid_cnn_gru_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad268d20",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM + CNN Model (overfits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "604d8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_bidirectional_lstm_cnn_model = models.Sequential([\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    layers.Bidirectional(layers.LSTM(64)),\n",
    "    layers.Reshape((128, 1)),\n",
    "    layers.Conv1D(64, 3, activation='relu'),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "hybrid_bidirectional_lstm_cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed6579",
   "metadata": {},
   "source": [
    "### 4.1 Train hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb75b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = hybrid_cnn_lstm_model # name of the model to be trained here\n",
    "\n",
    "history_hybrid = model.fit(X_train_scaled, y_train, epochs=30, validation_data=(X_test_scaled, y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"RNN Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5764b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0d4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a2db0a",
   "metadata": {},
   "source": [
    "# 5. All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a95fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fully Connected Neural Network...\n",
      "Fully Connected Neural Network Test Accuracy: 0.6823\n",
      "Training Deep and Wide FCNN...\n",
      "Deep and Wide FCNN Test Accuracy: 0.6970\n",
      "Training Shallow FCNN...\n",
      "Shallow FCNN Test Accuracy: 0.7081\n",
      "Training Batch Normalized FCNN...\n",
      "Batch Normalized FCNN Test Accuracy: 0.7000\n",
      "Training FCNN with Alternative Activations...\n",
      "FCNN with Alternative Activations Test Accuracy: 0.7308\n",
      "Training Regularized FCNN...\n",
      "Regularized FCNN Test Accuracy: 0.7217\n",
      "Training Basic CNN...\n",
      "Basic CNN Test Accuracy: 0.7187\n",
      "Training Deep CNN...\n",
      "Deep CNN Test Accuracy: 0.6621\n",
      "Training Batch Normalized CNN...\n",
      "Batch Normalized CNN Test Accuracy: 0.7202\n",
      "Training Dilated CNN...\n",
      "Dilated CNN Test Accuracy: 0.7025\n",
      "Training Inception CNN...\n",
      "Inception CNN Test Accuracy: 0.7146\n",
      "Training Lightweight CNN...\n",
      "Lightweight CNN Test Accuracy: 0.6652\n",
      "Training Basic RNN...\n",
      "Basic RNN Test Accuracy: 0.7056\n",
      "Training Simple RNN with Increased Depth...\n",
      "Simple RNN with Increased Depth Test Accuracy: 0.7000\n",
      "Training Bidirectional LSTM...\n",
      "Bidirectional LSTM Test Accuracy: 0.7086\n",
      "Training GRU with Layer Normalization...\n",
      "GRU with Layer Normalization Test Accuracy: 0.6980\n",
      "Training Stacked LSTM...\n",
      "Stacked LSTM Test Accuracy: 0.6929\n",
      "Training Hybrid CNN-LSTM...\n",
      "Hybrid CNN-LSTM Test Accuracy: 0.6040\n",
      "Training Hybrid LSTM-CNN...\n",
      "Hybrid LSTM-CNN Test Accuracy: 0.4414\n",
      "Training Hybrid CNN-GRU...\n",
      "Hybrid CNN-GRU Test Accuracy: 0.6121\n",
      "Training Hybrid Bidirectional LSTM-CNN...\n",
      "Hybrid Bidirectional LSTM-CNN Test Accuracy: 0.5854\n",
      "Models ranked by test accuracy:\n",
      "FCNN with Alternative Activations: 0.7308\n",
      "Regularized FCNN: 0.7217\n",
      "Batch Normalized CNN: 0.7202\n",
      "Basic CNN: 0.7187\n",
      "Inception CNN: 0.7146\n",
      "Bidirectional LSTM: 0.7086\n",
      "Shallow FCNN: 0.7081\n",
      "Basic RNN: 0.7056\n",
      "Dilated CNN: 0.7025\n",
      "Batch Normalized FCNN: 0.7000\n",
      "Simple RNN with Increased Depth: 0.7000\n",
      "GRU with Layer Normalization: 0.6980\n",
      "Deep and Wide FCNN: 0.6970\n",
      "Stacked LSTM: 0.6929\n",
      "Fully Connected Neural Network: 0.6823\n",
      "Lightweight CNN: 0.6652\n",
      "Deep CNN: 0.6621\n",
      "Hybrid CNN-GRU: 0.6121\n",
      "Hybrid CNN-LSTM: 0.6040\n",
      "Hybrid Bidirectional LSTM-CNN: 0.5854\n",
      "Hybrid LSTM-CNN: 0.4414\n"
     ]
    }
   ],
   "source": [
    "# List of all models to be trained with their corresponding data reshaping requirements\n",
    "models_to_train = [\n",
    "    {'model': fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'Fully Connected Neural Network'},\n",
    "    {'model': deep_wide_fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'Deep and Wide FCNN'},\n",
    "    {'model': shallow_fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'Shallow FCNN'},\n",
    "    {'model': bn_fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'Batch Normalized FCNN'},\n",
    "    {'model': alt_act_fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'FCNN with Alternative Activations'},\n",
    "    {'model': reg_fcnn, 'data': (X_train_scaled, X_test_scaled), 'name': 'Regularized FCNN'},\n",
    "    {'model': cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Basic CNN'},\n",
    "    {'model': deep_cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Deep CNN'},\n",
    "    {'model': bn_cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Batch Normalized CNN'},\n",
    "    {'model': dilated_cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Dilated CNN'},\n",
    "    {'model': inception_cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Inception CNN'},\n",
    "    {'model': lightweight_cnn, 'data': (X_train_cnn, X_test_cnn), 'name': 'Lightweight CNN'},\n",
    "    {'model': rnn, 'data': (X_train_rnn, X_test_rnn), 'name': 'Basic RNN'},\n",
    "    {'model': simple_rnn, 'data': (X_train_rnn, X_test_rnn), 'name': 'Simple RNN with Increased Depth'},\n",
    "    {'model': bidirectional_lstm, 'data': (X_train_rnn, X_test_rnn), 'name': 'Bidirectional LSTM'},\n",
    "    {'model': gru, 'data': (X_train_rnn, X_test_rnn), 'name': 'GRU with Layer Normalization'},\n",
    "    {'model': stacked_lstm, 'data': (X_train_rnn, X_test_rnn), 'name': 'Stacked LSTM'},\n",
    "    {'model': hybrid_cnn_lstm_model, 'data': (X_train_scaled, X_test_scaled), 'name': 'Hybrid CNN-LSTM'},\n",
    "    {'model': hybrid_lstm_cnn_model, 'data': (X_train_scaled, X_test_scaled), 'name': 'Hybrid LSTM-CNN'},\n",
    "    {'model': hybrid_cnn_gru_model, 'data': (X_train_scaled, X_test_scaled), 'name': 'Hybrid CNN-GRU'},\n",
    "    {'model': hybrid_bidirectional_lstm_cnn_model, 'data': (X_train_scaled, X_test_scaled), 'name': 'Hybrid Bidirectional LSTM-CNN'}\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Training and evaluating each model\n",
    "for entry in models_to_train:\n",
    "    model = entry['model']\n",
    "    X_train, X_test = entry['data']\n",
    "    y_train, y_test = y_train, y_test  # Assuming y_train and y_test are defined globally\n",
    "\n",
    "    print(f\"Training {entry['name']}...\")\n",
    "    history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"{entry['name']} Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    results.append({'model': entry['name'], 'accuracy': test_acc})\n",
    "\n",
    "# Sorting results by accuracy\n",
    "sorted_results = sorted(results, key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "# Displaying sorted results\n",
    "print(\"Models ranked by test accuracy:\")\n",
    "for result in sorted_results:\n",
    "    print(f\"{result['model']}: {result['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b2361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f8b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4907495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96561b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
